steps:
  - name: debian:11-slim
    args:
      - '-c'
      - |
        set -x
        set -o errexit
        set -o nounset
        set -o pipefail
        find . | sed -e "s/[^-][^\/]*\// |/g" -e "s/|\([^ ]\)/|-\1/"
        cat /etc/*-release
        whereis python3
        DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y tzdata sudo curl  > /dev/null
        source scripts/install_python3.9.sh
        source scripts/install_development_dependencies.sh --silent > /dev/null
        echo "common
        --remote_cache=https://storage.googleapis.com/${_GCS_BAZEL_CACHE}"
        >> .bazelrc
        echo "common --google_default_credentials" >> .bazelrc
        env
        make addlicense
        make check
        make build
        make test-pip-install
        make test -- --run-dataplex
        source scripts/install_gcloud.sh
        gsutil cp clouddq_patched.zip gs://$_GCS_BUCKET_NAME/build-artifacts/debian11/python3.9/`date -I`/`date -Iseconds`_${SHORT_SHA}/clouddq-executable.zip
        gsutil cp clouddq_patched.zip.hashsum gs://$_GCS_BUCKET_NAME/build-artifacts/debian11/python3.9/`date -I`/`date -Iseconds`_${SHORT_SHA}/clouddq-executable.zip.hashsum
    entrypoint: /bin/bash
    env:
    - 'GOOGLE_CLOUD_PROJECT=${_GOOGLE_CLOUD_PROJECT}'
    - 'CLOUDDQ_BIGQUERY_DATASET=${_CLOUDDQ_BIGQUERY_DATASET}'
    - 'CLOUDDQ_BIGQUERY_REGION=${_CLOUDDQ_BIGQUERY_REGION}'
    - 'GCS_BUCKET_NAME=${_GCS_BUCKET_NAME}'
    - 'DATAPLEX_LAKE_NAME=${_DATAPLEX_LAKE_NAME}'
    - 'DATAPLEX_REGION_ID=${_DATAPLEX_REGION_ID}'
    - 'DATAPLEX_ENDPOINT=${_DATAPLEX_ENDPOINT}'
    - 'DATAPLEX_TARGET_BQ_DATASET=${_DATAPLEX_TARGET_BQ_DATASET}'
    - 'DATAPLEX_TARGET_BQ_TABLE=${_DATAPLEX_TARGET_BQ_TABLE}'
    - 'DATAPLEX_TASK_SA=${_DATAPLEX_TASK_SA}'
  - name: ubuntu:18.04
    args:
      - '-c'
      - |
        set -x
        set -o errexit
        set -o nounset
        set -o pipefail
        find . | sed -e "s/[^-][^\/]*\// |/g" -e "s/|\([^ ]\)/|-\1/"
        cat /etc/*-release
        whereis python3
        DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y tzdata sudo curl  > /dev/null
        source scripts/install_python3.9.sh
        source scripts/install_development_dependencies.sh --silent > /dev/null
        echo "common
        --remote_cache=https://storage.googleapis.com/${_GCS_BAZEL_CACHE}"
        >> .bazelrc
        echo "common --google_default_credentials" >> .bazelrc
        env
        make addlicense
        make check
        make build
        make test-pip-install
        make test -- --run-dataplex
        source scripts/install_gcloud.sh
        gsutil cp clouddq_patched.zip gs://$_GCS_BUCKET_NAME/build-artifacts/ubuntu1804/python3.9/`date -I`/`date -Iseconds`_${SHORT_SHA}/clouddq-executable.zip
        gsutil cp clouddq_patched.zip.hashsum gs://$_GCS_BUCKET_NAME/build-artifacts/ubuntu1804/python3.9/`date -I`/`date -Iseconds`_${SHORT_SHA}/clouddq-executable.zip.hashsum
    entrypoint: /bin/bash
    env:
    - 'GOOGLE_CLOUD_PROJECT=${_GOOGLE_CLOUD_PROJECT}'
    - 'CLOUDDQ_BIGQUERY_DATASET=${_CLOUDDQ_BIGQUERY_DATASET}'
    - 'CLOUDDQ_BIGQUERY_REGION=${_CLOUDDQ_BIGQUERY_REGION}'
    - 'GCS_BUCKET_NAME=${_GCS_BUCKET_NAME}'
    - 'DATAPLEX_LAKE_NAME=${_DATAPLEX_LAKE_NAME}'
    - 'DATAPLEX_REGION_ID=${_DATAPLEX_REGION_ID}'
    - 'DATAPLEX_ENDPOINT=${_DATAPLEX_ENDPOINT}'
    - 'DATAPLEX_TARGET_BQ_DATASET=${_DATAPLEX_TARGET_BQ_DATASET}'
    - 'DATAPLEX_TARGET_BQ_TABLE=${_DATAPLEX_TARGET_BQ_TABLE}'
    - 'DATAPLEX_TASK_SA=${_DATAPLEX_TASK_SA}'
timeout: 7200s
logsBucket: gs://kthxbayes-bazel-cache
options:
  logStreamingOption: STREAM_ON
